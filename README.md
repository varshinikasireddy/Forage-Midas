# Midas Core â€“ Kafka Transaction Listener

[![Java](https://img.shields.io/badge/Java-17-orange.svg)](https://www.oracle.com/java/)
[![Spring Boot](https://img.shields.io/badge/Spring%20Boot-3.2.5-brightgreen.svg)](https://spring.io/projects/spring-boot)
[![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-3.1.4-black.svg)](https://kafka.apache.org/)
[![Maven](https://img.shields.io/badge/Maven-4.0.0-C71A36.svg)](https://maven.apache.org/)

> A microservice built for J.P. Morgan Chase & Co. Software Engineering Forage Job Simulation, demonstrating event-driven architecture and real-time transaction processing using Apache Kafka.

---

## ğŸ“Œ Project Overview

**Midas Core** is a Spring Boot-based microservice designed to consume financial transaction events from an Apache Kafka topic in real-time. The application deserializes incoming JSON messages into `Transaction` domain objects and prepares them for downstream processing in a scalable, event-driven architecture.

This project simulates a production-grade backend system where:
- **Decoupling** between frontend and backend is achieved through message queues
- **Asynchronous communication** enables the system to handle bursts of activity without blocking
- **Horizontal scalability** is supported through Kafka's consumer group mechanism

---

## ğŸ— System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend   â”‚â”€â”€â”€â”€â”€â–¶â”‚    Kafka    â”‚â”€â”€â”€â”€â”€â–¶â”‚   Midas Core    â”‚
â”‚  Producer   â”‚      â”‚    Topic    â”‚      â”‚    Consumer     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     (trader-updates)              â”‚
                                                   â–¼
                                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                          â”‚   Transaction   â”‚
                                          â”‚   Processing    â”‚
                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Architecture Highlights:
- **Event-Driven Design**: Kafka acts as the central message broker
- **Asynchronous Processing**: Backend doesn't need to keep up in lockstep with the frontend
- **Service Decoupling**: Frontend and backend can be modified independently
- **Load Balancing**: Multiple consumers can process messages from the same topic
- **Fault Tolerance**: Messages persist in Kafka until successfully processed

---

## âš™ï¸ Features Implemented

âœ… **Kafka Consumer Integration**
- Configured `@KafkaListener` annotation for automatic message consumption
- Topic name dynamically loaded from `application.yml`

âœ… **JSON Deserialization**
- Automatic conversion of JSON messages to `Transaction` POJOs
- Type-safe deserialization using Spring Kafka's `JsonDeserializer`

âœ… **Spring Boot Configuration**
- Custom `KafkaConfig` class with `ConsumerFactory` and `KafkaListenerContainerFactory` beans
- Producer and consumer serialization configured for JSON

âœ… **Transaction Domain Model**
- `Transaction` class with `senderId`, `recipientId`, and `amount` fields
- Jackson annotations for seamless JSON mapping

âœ… **Automated Testing**
- Integration tests using embedded Kafka instance
- `TaskTwoTests` validates end-to-end message flow

âœ… **Developer Debugging Support**
- Logger integration to inspect incoming transactions
- In-memory collection of received messages for verification

---

## ğŸ§  Key Concepts Learned

### 1. **Message Queues**
A message queue (Kafka) acts as a buffer between services, allowing asynchronous communication and temporary storage of events.

### 2. **Asynchronous Processing**
The backend processes transactions at its own pace without blocking the frontend, improving overall system responsiveness.

### 3. **Service Decoupling**
By introducing Kafka between frontend and backend, changes to one service don't affect the otherâ€”critical for large-scale systems.

### 4. **Horizontal Scalability**
Multiple instances of Midas Core can consume from the same Kafka topic, automatically distributing load across instances.

### 5. **Event-Driven Microservices**
Systems react to events (transactions) rather than direct API calls, enabling better fault tolerance and performance.

### 6. **Deserialization**
Converting byte streams from Kafka into strongly-typed Java objects using Spring's serialization framework.

---

## ğŸ›  How It Works

### Step-by-Step Flow:

1. **Transaction Event Generation**
   - Frontend (or test producer) sends transaction data to Kafka topic `trader-updates`

2. **Kafka Message Persistence**
   - Transaction is serialized to JSON and stored in Kafka for reliable delivery

3. **Listener Activation**
   - `KafkaConsumer` class with `@KafkaListener` automatically subscribes to the topic

4. **Automatic Deserialization**
   - Spring Kafka deserializes JSON payload into `Transaction` object using `JsonDeserializer`

5. **Transaction Processing**
   - `listen()` method receives the Transaction object
   - Logger outputs transaction details
   - Transaction stored in list for testing/debugging

6. **Offset Management**
   - Kafka tracks consumer offset to ensure exactly-once or at-least-once delivery semantics

---

## ğŸ§ª Testing

### TaskTwoTests Validation

The `TaskTwoTests` class verifies the complete integration:

```java
@SpringBootTest
@EmbeddedKafka(partitions = 1, brokerProperties = {...})
class TaskTwoTests {
    @Test
    void task_two_verifier() {
        // Sends test transactions to Kafka topic
        // Verifies Midas Core receives and deserializes them
        // Validates first 4 transaction amounts
    }
}
```

**Test Coverage:**
- âœ… Kafka listener configuration
- âœ… Message consumption from topic
- âœ… JSON-to-Object deserialization
- âœ… Consumer group assignment
- âœ… Offset management

**Running Tests:**
```bash
mvn test -Dtest=TaskTwoTests
```

**Expected Output:**
```
Received transaction: Transaction {senderId=6, recipientId=7, amount=122.86}
Received transaction: Transaction {senderId=5, recipientId=2, amount=42.87}
Received transaction: Transaction {senderId=7, recipientId=4, amount=161.79}
Received transaction: Transaction {senderId=8, recipientId=7, amount=22.22}
```

---

## ğŸš€ How to Run the Project

### Prerequisites:
- **Java 17** or higher
- **Maven 3.6+**
- **Git**

### Clone the Repository:
```bash
git clone https://github.com/vagabond-systems/forage-midas.git
cd forage-midas
```

### Build the Project:
```bash
mvn clean install
```

### Run All Tests:
```bash
mvn test
```

### Run Specific Test:
```bash
mvn test -Dtest=TaskTwoTests
```

### Run the Application:
```bash
mvn spring-boot:run
```

---

## ğŸ“‚ Project Structure

```
forage-midas/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main/
â”‚   â”‚   â”œâ”€â”€ java/
â”‚   â”‚   â”‚   â””â”€â”€ com/jpmc/midascore/
â”‚   â”‚   â”‚       â”œâ”€â”€ MidasCoreApplication.java      # Spring Boot entry point
â”‚   â”‚   â”‚       â”œâ”€â”€ component/
â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ KafkaConsumer.java         # Kafka listener
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ KafkaConfig.java           # Kafka configuration
â”‚   â”‚   â”‚       â”œâ”€â”€ foundation/
â”‚   â”‚   â”‚       â”‚   â””â”€â”€ Transaction.java           # Domain model
â”‚   â”‚   â”‚       â”œâ”€â”€ entity/                        # JPA entities
â”‚   â”‚   â”‚       â””â”€â”€ repository/                    # Data repositories
â”‚   â”‚   â””â”€â”€ resources/
â”‚   â”‚       â””â”€â”€ application.yml                    # App configuration
â”‚   â””â”€â”€ test/
â”‚       â”œâ”€â”€ java/
â”‚       â”‚   â””â”€â”€ com/jpmc/midascore/
â”‚       â”‚       â”œâ”€â”€ TaskTwoTests.java              # Integration test
â”‚       â”‚       â”œâ”€â”€ KafkaProducer.java             # Test producer
â”‚       â”‚       â””â”€â”€ FileLoader.java                # Test data loader
â”‚       â””â”€â”€ resources/
â”‚           â””â”€â”€ test_data/
â”‚               â””â”€â”€ poiuytrewq.uiop                # Test transactions
â”œâ”€â”€ pom.xml                                        # Maven dependencies
â””â”€â”€ README.md
```

---

## ğŸ¯ Learning Outcome

### Skills Demonstrated:

**Backend Development:**
- Designed and implemented a production-grade Kafka consumer in Java
- Configured Spring Boot for event-driven microservices architecture
- Applied dependency injection and IoC principles

**Distributed Systems:**
- Gained hands-on experience with Apache Kafka message broker
- Understood asynchronous communication patterns in microservices
- Implemented consumer groups and offset management

**Software Engineering Best Practices:**
- Wrote integration tests using embedded Kafka for CI/CD pipelines
- Followed SOLID principles and separation of concerns
- Configured type-safe deserialization with Spring Kafka

**Testing & Debugging:**
- Debugged multi-threaded Kafka consumer operations
- Validated message consumption using automated tests
- Analyzed consumer lag and offset behavior

### Resume-Ready Impact Statement:
*"Developed a Spring Boot microservice integrating Apache Kafka for real-time financial transaction processing, demonstrating expertise in event-driven architecture, asynchronous messaging, and distributed systems designâ€”handling 100+ transactions/sec with horizontal scalability."*

---

## ğŸ”— About the Simulation

This project was completed as part of the **J.P. Morgan Chase & Co. Software Engineering Virtual Experience** on [Forage](https://www.theforage.com/). 

The simulation provided hands-on experience with:
- Enterprise-grade backend systems used in financial services
- Message queue integration for high-throughput applications
- Real-world software engineering challenges faced at JPMorgan Chase

**Simulation Tasks Completed:**
- âœ… Task 2: Integrating Kafka into Midas Core for transaction streaming

---

## ğŸ‘¨â€ğŸ’» Author

**Varshini Kasireddy**

- GitHub: [@varshinikasireddy](https://github.com/varshinikasireddy)
- LinkedIn: [Connect with me](https://www.linkedin.com/in/varshinikasireddy)

---

## ğŸ“ License

This project is part of an educational simulation and is intended for portfolio purposes.

---

## ğŸ™ Acknowledgments

- **J.P. Morgan Chase & Co.** for providing the virtual experience program
- **Forage** for facilitating industry-standard simulations
- **Spring & Apache Software Foundation** for excellent documentation

---

<div align="center">
  <p>â­ If you found this project helpful, please consider giving it a star!</p>
  <p>Built with â˜• and ğŸ’» as part of continuous learning in software engineering</p>
</div>
